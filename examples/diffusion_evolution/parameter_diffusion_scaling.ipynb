{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train different Diffusion Model (DM) variants with different neural network backbones on a simple vector-target task",
   "id": "9fd0d1247b96109c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "b3516befcb37992a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Targets",
   "id": "e79761a51af9c53f"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "targets = [[0.5, 2.],\n",
    "           [-0.5, 2.],\n",
    "           [0.8, -2.],\n",
    "           [0.5, -3.5],\n",
    "           [0., -4],\n",
    "           [-0.5, -3.5],\n",
    "           [-0.8, -2.],\n",
    "           ]\n",
    "#\n",
    "targets = np.array(targets) - [10, 20]\n",
    "# targets = np.array(targets) - [10, 20]\n",
    "\n",
    "fitness = [1., ]  * len(targets)\n",
    "fitness = np.array(fitness)"
   ],
   "id": "b2ca0b0adc0a97bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(targets[:, 0], targets[:, 1], c='r', marker='^', s=100, label='Targets')\n",
    "ax.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "fa584276b8911744",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports & Helpers",
   "id": "f2ad995f7c8957cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from condevo.diffusion import RectFlow, DDIM\n",
    "from condevo.nn import MLP, UNet\n",
    "from condevo.es.utils import roulette_wheel"
   ],
   "id": "364b147934931ffa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_params = targets.shape[-1]\n",
    "\n",
    "def get_mlp(num_hidden=96,\n",
    "            num_layers=6,\n",
    "            activation=\"ReLU\",\n",
    "            dropout=0.0,\n",
    "            layer_norm=False,\n",
    "            batch_norm=False,\n",
    "            time_embedding=0,  # 0: disable, >1: train linear projection layer for time embedding\n",
    "            ):\n",
    "    return MLP(num_params=num_params, num_hidden=num_hidden, num_layers=num_layers, activation=activation, dropout=dropout, layer_norm=layer_norm, batch_norm=batch_norm, time_embedding=time_embedding)\n",
    "\n",
    "def get_unet(num_hidden=[64, 32, 16],  # encoding side of the \"U\"\n",
    "             activation=\"GELU\",\n",
    "             dropout=0.0,\n",
    "             layer_norm=True,\n",
    "             batch_norm=False,\n",
    "             time_embedding=0,\n",
    "             ):\n",
    "    return UNet(num_params=num_params, num_hidden=num_hidden, activation=activation, dropout=dropout, layer_norm=layer_norm, batch_norm=batch_norm, time_embedding=time_embedding)\n"
   ],
   "id": "3b150c69ceb4aaf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_ddim(model, backbone,\n",
    "             skip_connection=False,\n",
    "             num_steps=300,\n",
    "             alpha_schedule=\"cosine_nichol\",\n",
    "             noise_level=1.0,\n",
    "             clip_gradients=1.,\n",
    "             scaler=None,\n",
    "             ):\n",
    "    log_dir = f\"data/ddim_{backbone}\"\n",
    "    return DDIM(nn=model, skip_connection=skip_connection, num_steps=num_steps, alpha_schedule=alpha_schedule, noise_level=noise_level, clip_gradients=clip_gradients, log_dir=log_dir, scaler=scaler)\n",
    "\n",
    "\n",
    "def get_rflow(model, backbone,\n",
    "              num_steps=50,\n",
    "              noise_level=1.0,\n",
    "              clip_gradients=1.,\n",
    "              scaler=None,\n",
    "              ):\n",
    "    log_dir = f\"data/RFlow_{backbone}\"\n",
    "\n",
    "    return RectFlow(nn=model, num_steps=num_steps, noise_level=noise_level, clip_gradients=clip_gradients, log_dir=log_dir, scaler=scaler)\n"
   ],
   "id": "7267a9ed7fe220e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T10:26:11.122585078Z",
     "start_time": "2026-01-05T10:26:11.093430670Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Train DDIM model with MLP backbone",
   "id": "1df2cedde3f4e19d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_size = 1000\n",
    "max_epochs   =  500\n",
    "device = \"cpu\"\n",
    "\n",
    "# augment dataset -> make dataset large enough so learning progress is smooth\n",
    "weights = roulette_wheel(torch.tensor(fitness, dtype=torch.float), s=1, normalize=True)\n",
    "for t, f, w in zip(targets, fitness, weights):\n",
    "    print(f\"target {t} with fitness {f} is weighted as {w}\")\n",
    "\n",
    "target_idx_training = np.random.choice(np.arange(len(targets)), size=dataset_size, p=None, replace=True)\n",
    "\n",
    "# convert to torch tensors\n",
    "x = torch.tensor(targets[target_idx_training], dtype=torch.float).to(device)\n",
    "f = weights[target_idx_training][:, None].to(device)\n",
    "\n",
    "# initialize model\n",
    "backbone = get_mlp()\n",
    "# backbone = get_unet()\n",
    "ddim = get_ddim(model=backbone, backbone=\"unet_test\")\n",
    "ddim = ddim.to(device)\n",
    "\n",
    "# train\n",
    "history = ddim.fit(\n",
    "    x,\n",
    "    weights=f,\n",
    "    max_epoch=max_epochs,\n",
    "    lr=3e-3,\n",
    "    optimizer=\"Adam\",\n",
    "    weight_decay=1e-5,\n",
    ")"
   ],
   "id": "89247c09679d7f21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples = ddim.sample(shape=(num_params,), num=1000)\n",
    "\n",
    "count = []\n",
    "for t in targets:\n",
    "    dt = torch.linalg.norm(samples - t, dim=-1)\n",
    "    count.append((dt < 0.25).sum().item() / len(samples))\n",
    "\n",
    "for t, f, w, c in zip(targets, fitness, weights, count):\n",
    "    print(f\"target {t} weighted by {w:.3f}: sampling rate {c}\")"
   ],
   "id": "d8094045ba541829",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, (ax_hist, ax) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax_hist.plot(history)\n",
    "ax_hist.set_xlabel(\"Epochs\")\n",
    "ax_hist.set_ylabel(\"Loss\")\n",
    "ax_hist.grid()\n",
    "\n",
    "ax.scatter(samples[:, 0], samples[:, 1], c='b', marker='o', alpha=0.5)\n",
    "ax.scatter(targets[:, 0], targets[:, 1], c='r', marker='^', s=100, label='Targets')\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "id": "276d4543802e1d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analyze the denoising stack of DDIM models",
   "id": "d613cc7b9f066258"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, num_samples, num_params, t_start=None):\n",
    "    # sample entire denoising stack (num_(t_)steps, num_samples, num_params) for t in [T, 0]\n",
    "    if t_start is None:\n",
    "        t_start = model.num_steps - 1\n",
    "\n",
    "    xt = torch.randn(t_start + 1, num_samples, num_params)  # RETURN entire denoising stack\n",
    "    one = torch.ones(num_samples, 1, device=xt.device, dtype=xt.dtype)\n",
    "\n",
    "    for T in range(t_start, 0, -1):\n",
    "        t = one * model._step_discrete_to_continuous(T)\n",
    "        a = model.alpha[T-1]\n",
    "        s = model.sigma[T] * model.noise_level\n",
    "        z = torch.randn_like(xt[T])\n",
    "\n",
    "        eps = model.predict_eps(xt[T], t)\n",
    "        eps, x0_pred = model.get_clamped_eps_x0(xt[T], eps, T)\n",
    "\n",
    "        eps_sqrt_term = (1 - a - s ** 2).clamp_min(0).sqrt()\n",
    "        xt[T-1] = a.sqrt() * x0_pred + eps_sqrt_term * eps + s * z\n",
    "\n",
    "    return model.scaler.inverse_transform(xt)"
   ],
   "id": "624b88fe31ee82c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from condevo.stats import kl_divergence_sampled\n",
    "from condevo.stats import grid_entropy_2d\n",
    "\n",
    "# generate PD from target x according to fitness\n",
    "pd_size = 2000\n",
    "p = np.array(weights)\n",
    "p /= p.sum()\n",
    "idx = np.random.choice(np.arange(len(targets)), p=p, size=pd_size)\n",
    "px = x[idx]\n",
    "\n",
    "# sample data\n",
    "samples = sample(ddim, 1000, 2)\n",
    "\n",
    "# eval statistics\n",
    "grid_size = 33\n",
    "grid_range = 4  # ddim.diff_range\n",
    "print(\"binsize =\", grid_range * 2 / (grid_size - 1))\n",
    "entropy = [grid_entropy_2d(xt, grid_size=grid_size, range_min=-grid_range, range_max=grid_range) for xt in reversed(samples)]\n",
    "KL_divergence = [kl_divergence_sampled(px, px_hat, grid_size=grid_size, range_min=-grid_range, range_max=grid_range) for px_hat in reversed(samples)]\n",
    "\n",
    "# plot statistics\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = plt.gca()\n",
    "ax.plot(np.arange(ddim.num_steps), KL_divergence)\n",
    "ax.set_ylabel(\"KL-Divergence\")\n",
    "ax.set_xlabel(\"Denoising steps $(t-T)$\")\n",
    "\n",
    "t_ax = plt.twinx()\n",
    "t_ax.plot([], label=\"KL-Divergence\")\n",
    "t_ax.plot(np.arange(ddim.num_steps), entropy, color=\"tab:orange\", label=\"Entropy\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "1347cc28b7be7b32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##### plot denoising over time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "samples = sample(ddim, 1000, 2)\n",
    "\n",
    "T, N, _ = samples.shape\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Ensure numpy float array (handles torch tensors too)\n",
    "samples_np = np.asarray(samples, dtype=float)[::-1]\n",
    "\n",
    "# Fixed limits\n",
    "lims = [(samples_np[..., i].min(), samples_np[..., i].max()) for i in range(2)]\n",
    "ax.set_xlim(lims[0]); ax.set_ylim(lims[1]);\n",
    "#ax.set_xlim([-20, 20]); ax.set_ylim([-30, 20]);\n",
    "\n",
    "# Init\n",
    "xy0 = samples_np[0]\n",
    "scat = ax.scatter(xy0[:, 0], xy0[:, 1], s=5, alpha=0.8)\n",
    "title = ax.set_title(\"t = 0\")\n",
    "\n",
    "def update(frame):\n",
    "    xy = samples_np[frame]              # (N, 2)\n",
    "    scat.set_offsets(xy[:, :2])\n",
    "    title.set_text(f\"t = {frame}\")\n",
    "    return scat, title\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=T, interval=50, blit=False)\n",
    "\n",
    "display(HTML(anim.to_jshtml()))"
   ],
   "id": "b764381cd34b94e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The animation shows some important features:\n",
    "- First, the particle cloud (the to-be-generated samples) expands from the origin towards the target loation (near [-10, -20])\n",
    "- Then, it separates hierarchically into the respective revined clouds\n",
    "\n",
    "The diffusion model needs to learn, is the initial drivt towards the target data regime.\n",
    "\n",
    "**Importantly: if the number of denoising steps don't suffice, the diffusion might not reach the target regime in time. Try a dataset biased by a mean of [-100, -200], for instance.**\n",
    "\n",
    "For such cases, data scaling will be important! Below, we present the same results with a simple MEAN / STD `StandardScaler`"
   ],
   "id": "52a822e6ca02da4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using a StandardScaler",
   "id": "21310507ffd71635"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DDIM",
   "id": "84600bf6afbe977b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "dataset_size = 1000\n",
    "max_epochs   =  500\n",
    "device = \"cpu\"\n",
    "\n",
    "# augment dataset -> make dataset large enough so learning progress is smooth\n",
    "weights = roulette_wheel(torch.tensor(fitness, dtype=torch.float), s=1, normalize=True)\n",
    "for t, f, w in zip(targets, fitness, weights):\n",
    "    print(f\"target {t} with fitness {f} is weighted as {w}\")\n",
    "\n",
    "target_idx_training = np.random.choice(np.arange(len(targets)), size=dataset_size, p=None, replace=True)\n",
    "\n",
    "# convert to torch tensors\n",
    "x = torch.tensor(targets[target_idx_training], dtype=torch.float).to(device)\n",
    "f = weights[target_idx_training][:, None].to(device)\n",
    "\n",
    "# initialize model\n",
    "backbone = get_mlp()\n",
    "# backbone = get_unet()\n",
    "ddim = get_ddim(model=backbone,\n",
    "                backbone=\"mlp_test\",\n",
    "                scaler=\"StandardScaler\",  # <-- this is implemented in condevo.preprocessing.starndard_scaler\n",
    "                )\n",
    "ddim = ddim.to(device)\n",
    "\n",
    "# train\n",
    "history = ddim.fit(\n",
    "    x,\n",
    "    weights=f,\n",
    "    max_epoch=max_epochs,\n",
    "    lr=3e-3,\n",
    "    optimizer=\"Adam\",\n",
    "    weight_decay=1e-5,\n",
    ")"
   ],
   "id": "f8ad2c002f05170e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ddim.scaler.mean, ddim.scaler.std",
   "id": "5d853f7d8f200bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples = ddim.sample(shape=(num_params,), num=1000)\n",
    "\n",
    "count = []\n",
    "for t in targets:\n",
    "    dt = torch.linalg.norm(samples - t, dim=-1)\n",
    "    count.append((dt < 0.25).sum().item() / len(samples))\n",
    "\n",
    "for t, f, w, c in zip(targets, fitness, weights, count):\n",
    "    print(f\"target {t} weighted by {w:.3f}: sampling rate {c}\")\n",
    "\n",
    "fig, (ax_hist, ax) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax_hist.plot(history)\n",
    "ax_hist.set_xlabel(\"Epochs\")\n",
    "ax_hist.set_ylabel(\"Loss\")\n",
    "ax_hist.grid()\n",
    "\n",
    "ax.scatter(samples[:, 0], samples[:, 1], c='b', marker='o', alpha=0.5)\n",
    "ax.scatter(targets[:, 0], targets[:, 1], c='r', marker='^', s=100, label='Targets')\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "id": "f8d4a335a5979af5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##### plot denoising over time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "samples = sample(ddim, 500, 2)\n",
    "\n",
    "T, N, _ = samples.shape\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Ensure numpy float array (handles torch tensors too)\n",
    "samples_np = np.asarray(samples, dtype=float)[::-1]\n",
    "\n",
    "# Fixed limits\n",
    "lims = [(samples_np[..., i].min(), samples_np[..., i].max()) for i in range(2)]\n",
    "ax.set_xlim(lims[0]); ax.set_ylim(lims[1]);\n",
    "# ax.set_xlim([-20, 20]); ax.set_ylim([-20, 20]);\n",
    "\n",
    "# Init\n",
    "xy0 = samples_np[0]\n",
    "scat = ax.scatter(xy0[:, 0], xy0[:, 1], s=5, alpha=0.8)\n",
    "title = ax.set_title(\"t = 0\")\n",
    "\n",
    "def update(frame):\n",
    "    xy = samples_np[frame]              # (N, 2)\n",
    "    scat.set_offsets(xy[:, :2])\n",
    "    title.set_text(f\"t = {frame}\")\n",
    "    return scat, title\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=T, interval=50, blit=False)\n",
    "\n",
    "display(HTML(anim.to_jshtml()))"
   ],
   "id": "96cdad5f3e83a2d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rectified Flow",
   "id": "b17e12e9cd6fa67f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "dataset_size = 1000\n",
    "max_epochs   =  500\n",
    "device = \"cpu\"\n",
    "\n",
    "# augment dataset -> make dataset large enough so learning progress is smooth\n",
    "weights = roulette_wheel(torch.tensor(fitness, dtype=torch.float), s=1, normalize=True)\n",
    "for t, f, w in zip(targets, fitness, weights):\n",
    "    print(f\"target {t} with fitness {f} is weighted as {w}\")\n",
    "\n",
    "target_idx_training = np.random.choice(np.arange(len(targets)), size=dataset_size, p=None, replace=True)\n",
    "\n",
    "# convert to torch tensors\n",
    "x = torch.tensor(targets[target_idx_training], dtype=torch.float).to(device)\n",
    "f = weights[target_idx_training][:, None].to(device)\n",
    "\n",
    "# initialize model\n",
    "backbone = get_mlp()\n",
    "# backbone = get_unet()\n",
    "rflow = get_rflow(model=backbone, backbone=\"unet_test\", scaler=\"StandardScaler\")\n",
    "rflow = rflow.to(device)\n",
    "\n",
    "# train\n",
    "history = rflow.fit(\n",
    "    x,\n",
    "    weights=f,\n",
    "    max_epoch=max_epochs,\n",
    "    lr=3e-3,\n",
    "    optimizer=\"Adam\",\n",
    "    weight_decay=1e-5,\n",
    ")"
   ],
   "id": "5ed9fd0250cb219a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples = rflow.sample(shape=(num_params,), num=1000)\n",
    "\n",
    "count = []\n",
    "for t in targets:\n",
    "    dt = torch.linalg.norm(samples - t, dim=-1)\n",
    "    count.append((dt < 0.25).sum().item() / len(samples))\n",
    "\n",
    "for t, f, w, c in zip(targets, fitness, weights, count):\n",
    "    print(f\"target {t} weighted by {w:.3f}: sampling rate {c}\")\n",
    "\n",
    "fig, (ax_hist, ax) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax_hist.plot(history)\n",
    "ax_hist.set_xlabel(\"Epochs\")\n",
    "ax_hist.set_ylabel(\"Loss\")\n",
    "ax_hist.grid()\n",
    "\n",
    "ax.scatter(samples[:, 0], samples[:, 1], c='b', marker='o', alpha=0.5)\n",
    "ax.scatter(targets[:, 0], targets[:, 1], c='r', marker='^', s=100, label='Targets')\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "id": "51d9595ef59225f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def rflow_sample(model, num_samples, num_params, t_start=None):\n",
    "    # sample entire denoising stack (num_(t_)steps, num_samples, num_params) for t in [T, 0]\n",
    "    if t_start is None:\n",
    "        t_start = 0\n",
    "\n",
    "    xtt = torch.randn(model.num_steps, num_samples, num_params)  # RETURN entire denoising stack\n",
    "    tt = torch.linspace(0, 1, model.num_steps, device=model.device).view(-1, 1)  # (T,1)\n",
    "    dt = 1. / model.num_steps * model.matthew_factor\n",
    "\n",
    "    xt = xtt[0]\n",
    "    for T in range(t_start, model.num_steps):\n",
    "        t = tt[T].expand(xt.size(0), 1)  # (B,1)\n",
    "        v = model(xt, t)\n",
    "        xt = xt + v * dt\n",
    "\n",
    "        if model.noise_level:\n",
    "            xt += (dt ** 0.5) * torch.randn_like(xt) * model.noise_level * (1 - t)\n",
    "\n",
    "        if model.diff_range_filter:\n",
    "            xt = model.diff_clamp(xt)\n",
    "\n",
    "        xtt[T, ...] = xt.clone()\n",
    "\n",
    "    return model.scaler.inverse_transform(xtt)"
   ],
   "id": "4b98d6a00352c7bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##### plot denoising over time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "samples = rflow_sample(rflow, 500, 2)\n",
    "\n",
    "T, N, _ = samples.shape\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Ensure numpy float array (handles torch tensors too)\n",
    "samples_np = np.asarray(samples, dtype=float)\n",
    "\n",
    "# Fixed limits\n",
    "lims = [(samples_np[..., i].min(), samples_np[..., i].max()) for i in range(2)]\n",
    "ax.set_xlim(lims[0]); ax.set_ylim(lims[1]);\n",
    "# ax.set_xlim([-20, 20]); ax.set_ylim([-20, 20]);\n",
    "\n",
    "# Init\n",
    "xy0 = samples_np[0]\n",
    "scat = ax.scatter(xy0[:, 0], xy0[:, 1], s=5, alpha=0.8)\n",
    "title = ax.set_title(\"t = 0\")\n",
    "\n",
    "def update(frame):\n",
    "    xy = samples_np[frame]              # (N, 2)\n",
    "    scat.set_offsets(xy[:, :2])\n",
    "    title.set_text(f\"t = {frame}\")\n",
    "    return scat, title\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=T, interval=50, blit=False)\n",
    "\n",
    "display(HTML(anim.to_jshtml()))"
   ],
   "id": "b463cf3db08f5e69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a4dc576fb0613c6d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
