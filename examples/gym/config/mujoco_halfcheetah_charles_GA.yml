experiment: MujocoHalfCheetah
timestamp: True
new_model: True
experiment_config:
#  agent: "GRU"
#  agent_kwargs:
#    num_hidden: 16
#    num_layers: 1
  agent: "QKV"
  agent_kwargs:
    action_foldback: True
    pos_embedding: False
    projection_size: 4
    embedding_size: 6
    query_size: 12
    context_size: 4
    num_heads: 3
    hidden_size: 8
  world_kwargs:
    n_episodes: 10
    log_fields: ["reward", "done", "observation"]
es: CHARLES
conditions:
  fitness_condition:                 # generate offspring conditional to fitness
    scale: 500                       # normalize the fitness by this value
    greedy: true                     # use greedy or Fisher-type sampling
  knn_novelty_condition:
    k: 48
    weight_by_fitness: true 
generations: 500
es_config:
  popsize: 128
  is_genetic_algorithm: False
  selection_pressure: 12.0           # selection pressure for roulette wheel selection
  adaptive_selection_pressure: True  # whether to adapt the selection pressure
  elite_ratio: 0.0625                # ratio of the population to keep as elite. If crossover is used, an additional copy of the elite solutions might be added to the population if `improvement_steps` is defined.
  crossover_ratio: 0.0625            # ratio of the population to perform crossover (if genetic algorithm, otherwise ignored)
  mutation_rate: 0.125               # mutation rate after crossover and sampling
  unbiased_mutation_ratio: 0.125     # ratio of the population to perform unbiased mutation (if genetic algorithm, otherwise ignored)
  readaptation: False                # whether to use mutation adaptation (denoising steps) or not. Only valid for `HADES` and `CHARLES` evolutionary strategies.
  forget_best: True                  # whether to forget the best solution, or keep the elites for the next generation
  weight_decay: 0.001                # L2 weight decay for the parameters of the evolutionary strategy (NOT of the diffusion model)
  diff_optim: "Adam"                 # DM: optimizer for training the diffusion model
  diff_lr: 0.003                     # DM: learning rate for training the diffusion model
  diff_weight_decay: 0.00000001      # DM: weight decay for training the diffusion model
  diff_batch_size: 32                # DM: batch size for training the diffusion model
  diff_max_epoch: 300                # DM: number of training steps for the diffusion model at each generation
  diff_continuous_training: False    # DM: continuous training, or retrain diffusion model at each generation
  buffer_size: 3 
  diversity_selection: False
diff: DDIM
diff_config:
  num_steps: 1000
  noise_level: 0.1
  diff_range: 10
  sample_uniform: False
  autoscaling: False
  skip_connection: False
nn: MLP
nn_config:
  num_hidden: 64
  num_layers: 2
  activation: ReLU
  batch_norm: True
  # dropout: 0.01
